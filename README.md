# MLB_HOF
Bootcamp Project 2

## Data Sources

* [The Lahman Baseball Database](http://www.seanlahman.com/baseball-archive/)
    Tables: CSV
* [Retro Sheet](https://www.retrosheet.org/)
    Tables: CSV
* [Baseball Hall of Fame](https://baseballhall.org/discover-more/awards)
    Tables: CSV
* [Baseball Reference](https://www.baseball-reference.com/)
    Tables: CSV
* [Wikipedia](www.wikipedia.com)
    Tables: CSV
* [Fangraphs](https://www.fangraphs.com/)
    Tables: CSV



## Data Cleanup & Analysis

With the above datasets identified, ETL was performed on the data. 

* The sources of data that you will extract from.

* The type of transformation needed for this data (cleaning, joining, filtering, aggregating, etc)All of the above

* The type of final production database to load the data into (relational or non-relational).
We opted to use Postgres (relational)

* The final tables or collections that will be used in the production database.

You will be required to submit a final technical report with the above information and steps required to reproduce your ETL process.

## Project Report

At the end of the week, your team will submit a Final Report that describes the following:

* **E**xtract: your original data sources and how the data was formatted (CSV, JSON, pgAdmin 4, etc).

* **T**ransform: what data cleaning or transformation was required.

* **L**oad: the final database, tables/collections, and why this was chosen.

Please upload the report to Github and submit a link to Bootcampspot.

- - -
